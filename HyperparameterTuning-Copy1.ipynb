{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B-Zz_NbBpmdG"
   },
   "source": [
    "# Hyperparameter Tuning using `GridSearchCV()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2284,
     "status": "ok",
     "timestamp": 1619472764834,
     "user": {
      "displayName": "Xianjun Geng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjp2zNPbIYU0DaDSSzFs4-oEwNRuLg3LhJILAgh3RY=s64",
      "userId": "03603659341670711497"
     },
     "user_tz": 300
    },
    "id": "b8AiVuH_phgT"
   },
   "outputs": [],
   "source": [
    "# load necessary Python packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('max_columns', 50)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 687,
     "status": "ok",
     "timestamp": 1619472768528,
     "user": {
      "displayName": "Xianjun Geng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjp2zNPbIYU0DaDSSzFs4-oEwNRuLg3LhJILAgh3RY=s64",
      "userId": "03603659341670711497"
     },
     "user_tz": 300
    },
    "id": "jsAPeTuHphgT"
   },
   "outputs": [],
   "source": [
    "# Load the balanced LendingClub dataset\n",
    "\n",
    "df = pd.read_csv('LendingClub_balanced.csv')\n",
    "\n",
    "X = df.drop(columns=['not_fully_paid'])\n",
    "y = df['not_fully_paid']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=365)\n",
    "X_train = X_train.copy()\n",
    "X_test = X_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Olhdzn9ktmOM"
   },
   "source": [
    "## Hyperparameters and model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "f3Ixu_rfJNA3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "When max_depth=2, the accuracy is: 57.33%\n",
      "The confusion matrix is:\n",
      "[[247  51]\n",
      " [211 105]]\n",
      "\n",
      "When max_depth=10, the accuracy is: 53.09%\n",
      "The confusion matrix is:\n",
      "[[205  93]\n",
      " [195 121]]\n"
     ]
    }
   ],
   "source": [
    "# Let's use the \"max_depth\" parameter in DecisionTreeClassifier as an example\n",
    "\n",
    "y_predict = DecisionTreeClassifier(max_depth=2, random_state=1).fit(X_train,y_train).predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_predict)\n",
    "print(f\"\\nWhen max_depth=2, the accuracy is: {accuracy:.2%}\")\n",
    "print(\"The confusion matrix is:\")\n",
    "print(confusion_matrix(y_test, y_predict))\n",
    "\n",
    "y_predict = DecisionTreeClassifier(max_depth=10, random_state=1).fit(X_train,y_train).predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_predict)\n",
    "print(f\"\\nWhen max_depth=10, the accuracy is: {accuracy:.2%}\")\n",
    "print(\"The confusion matrix is:\")\n",
    "print(confusion_matrix(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "f3Ixu_rfJNA3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "When the split criterion is 'gini', the accuracy is: 53.09%\n",
      "The confusion matrix is:\n",
      "[[205  93]\n",
      " [195 121]]\n",
      "\n",
      "When the split criterion is 'entropy', the accuracy is: 54.89%\n",
      "The confusion matrix is:\n",
      "[[209  89]\n",
      " [188 128]]\n"
     ]
    }
   ],
   "source": [
    "# Next try the \"criterion\" parameter\n",
    "\n",
    "y_predict = DecisionTreeClassifier(criterion='gini', max_depth=10, random_state=1).fit(X_train,y_train).predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_predict)\n",
    "print(f\"\\nWhen the split criterion is 'gini', the accuracy is: {accuracy:.2%}\")\n",
    "print(\"The confusion matrix is:\")\n",
    "print(confusion_matrix(y_test, y_predict))\n",
    "\n",
    "max_depth = 10\n",
    "y_predict = DecisionTreeClassifier(criterion='entropy', max_depth=10, random_state=1).fit(X_train,y_train).predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_predict)\n",
    "print(f\"\\nWhen the split criterion is 'entropy', the accuracy is: {accuracy:.2%}\")\n",
    "print(\"The confusion matrix is:\")\n",
    "print(confusion_matrix(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bEh7btIBw7XB"
   },
   "source": [
    "## Hyperparameter tuning using `GridSearchCV()`\n",
    "\n",
    "Suppose that we plan to train a `DecisionTreeClassifier`, and we want to decide between the following hyperparameter choices:\n",
    "+ for the tree splitting criterion, we wonder to use 'gini' or to use 'entropy'\n",
    "+ for the max depth of the tree, we wonder which to choose among 2, 4, 6, 8, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "KasN14GhPz_T",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GridSearchCV() is the popular choice for hyper-parameter tuning\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "KasN14GhPz_T",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'criterion': 'entropy', 'max_depth': 4}\n",
      "The cross-validation accuracy is: 0.5889\n",
      "The testing accuracy is: 0.5798\n",
      "The confusion matrix is:\n",
      "[[228  70]\n",
      " [188 128]]\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "param_grid = {\n",
    "    'criterion' : [\"gini\", \"entropy\"],\n",
    "    'max_depth': np.arange(2,11,2)\n",
    "#    'max_depth': [2,4,6,8,10]\n",
    "}    \n",
    "\n",
    "grid = GridSearchCV(estimator = clf, param_grid = param_grid, cv=3)\n",
    "grid.fit(X_train, y_train)\n",
    "print(f\"Best parameters are: {grid.best_params_}\")\n",
    "print(f\"The cross-validation accuracy is: {round(grid.best_score_,4)}\")\n",
    "\n",
    "# evaluation\n",
    "y_predict = grid.best_estimator_.predict(X_test)\n",
    "print(f\"The testing accuracy is: {accuracy_score(y_test, y_predict).round(4)}\")\n",
    "print(\"The confusion matrix is:\")\n",
    "cm = confusion_matrix(y_test, y_predict)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding `GridSearchCV()`: the grid search process\n",
    "\n",
    "Simply put, `GridSearchCV()` tries every possible combination of hyperparameter values, and then select the best one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.008942</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>0.002917</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2}</td>\n",
       "      <td>0.559902</td>\n",
       "      <td>0.602203</td>\n",
       "      <td>0.596083</td>\n",
       "      <td>0.586063</td>\n",
       "      <td>0.018666</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.011279</td>\n",
       "      <td>0.001507</td>\n",
       "      <td>0.003477</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 4}</td>\n",
       "      <td>0.579462</td>\n",
       "      <td>0.613219</td>\n",
       "      <td>0.572827</td>\n",
       "      <td>0.588503</td>\n",
       "      <td>0.017686</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.014090</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.003195</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 6}</td>\n",
       "      <td>0.570905</td>\n",
       "      <td>0.577723</td>\n",
       "      <td>0.585067</td>\n",
       "      <td>0.577898</td>\n",
       "      <td>0.005783</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.013831</td>\n",
       "      <td>0.001032</td>\n",
       "      <td>0.002463</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>gini</td>\n",
       "      <td>8</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 8}</td>\n",
       "      <td>0.557457</td>\n",
       "      <td>0.588739</td>\n",
       "      <td>0.585067</td>\n",
       "      <td>0.577088</td>\n",
       "      <td>0.013962</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.015453</td>\n",
       "      <td>0.000590</td>\n",
       "      <td>0.007924</td>\n",
       "      <td>0.007090</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10}</td>\n",
       "      <td>0.572127</td>\n",
       "      <td>0.575275</td>\n",
       "      <td>0.555692</td>\n",
       "      <td>0.567698</td>\n",
       "      <td>0.008587</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.008812</td>\n",
       "      <td>0.001086</td>\n",
       "      <td>0.002704</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2}</td>\n",
       "      <td>0.557457</td>\n",
       "      <td>0.602203</td>\n",
       "      <td>0.596083</td>\n",
       "      <td>0.585248</td>\n",
       "      <td>0.019809</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.011130</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.002595</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 4}</td>\n",
       "      <td>0.574572</td>\n",
       "      <td>0.614443</td>\n",
       "      <td>0.577723</td>\n",
       "      <td>0.588913</td>\n",
       "      <td>0.018098</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.013544</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.002682</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>entropy</td>\n",
       "      <td>6</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 6}</td>\n",
       "      <td>0.556235</td>\n",
       "      <td>0.608323</td>\n",
       "      <td>0.588739</td>\n",
       "      <td>0.584432</td>\n",
       "      <td>0.021482</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.016885</td>\n",
       "      <td>0.001278</td>\n",
       "      <td>0.002353</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>entropy</td>\n",
       "      <td>8</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 8}</td>\n",
       "      <td>0.547677</td>\n",
       "      <td>0.615667</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.580764</td>\n",
       "      <td>0.027786</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.018838</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>0.003183</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10}</td>\n",
       "      <td>0.555012</td>\n",
       "      <td>0.603427</td>\n",
       "      <td>0.565483</td>\n",
       "      <td>0.574641</td>\n",
       "      <td>0.020799</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.008942      0.000473         0.002917        0.000492   \n",
       "1       0.011279      0.001507         0.003477        0.000684   \n",
       "2       0.014090      0.001400         0.003195        0.000410   \n",
       "3       0.013831      0.001032         0.002463        0.000085   \n",
       "4       0.015453      0.000590         0.007924        0.007090   \n",
       "5       0.008812      0.001086         0.002704        0.000204   \n",
       "6       0.011130      0.000600         0.002595        0.000151   \n",
       "7       0.013544      0.000266         0.002682        0.000155   \n",
       "8       0.016885      0.001278         0.002353        0.000037   \n",
       "9       0.018838      0.000359         0.003183        0.000574   \n",
       "\n",
       "  param_criterion param_max_depth                                     params  \\\n",
       "0            gini               2      {'criterion': 'gini', 'max_depth': 2}   \n",
       "1            gini               4      {'criterion': 'gini', 'max_depth': 4}   \n",
       "2            gini               6      {'criterion': 'gini', 'max_depth': 6}   \n",
       "3            gini               8      {'criterion': 'gini', 'max_depth': 8}   \n",
       "4            gini              10     {'criterion': 'gini', 'max_depth': 10}   \n",
       "5         entropy               2   {'criterion': 'entropy', 'max_depth': 2}   \n",
       "6         entropy               4   {'criterion': 'entropy', 'max_depth': 4}   \n",
       "7         entropy               6   {'criterion': 'entropy', 'max_depth': 6}   \n",
       "8         entropy               8   {'criterion': 'entropy', 'max_depth': 8}   \n",
       "9         entropy              10  {'criterion': 'entropy', 'max_depth': 10}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  mean_test_score  \\\n",
       "0           0.559902           0.602203           0.596083         0.586063   \n",
       "1           0.579462           0.613219           0.572827         0.588503   \n",
       "2           0.570905           0.577723           0.585067         0.577898   \n",
       "3           0.557457           0.588739           0.585067         0.577088   \n",
       "4           0.572127           0.575275           0.555692         0.567698   \n",
       "5           0.557457           0.602203           0.596083         0.585248   \n",
       "6           0.574572           0.614443           0.577723         0.588913   \n",
       "7           0.556235           0.608323           0.588739         0.584432   \n",
       "8           0.547677           0.615667           0.578947         0.580764   \n",
       "9           0.555012           0.603427           0.565483         0.574641   \n",
       "\n",
       "   std_test_score  rank_test_score  \n",
       "0        0.018666                3  \n",
       "1        0.017686                2  \n",
       "2        0.005783                7  \n",
       "3        0.013962                8  \n",
       "4        0.008587               10  \n",
       "5        0.019809                4  \n",
       "6        0.018098                1  \n",
       "7        0.021482                5  \n",
       "8        0.027786                6  \n",
       "9        0.020799                9  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now print out all combinations below just for our learning. In practice, we usually \n",
    "# care only about the combination that results in the best score.\n",
    "pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding `GridSearchCV()`: the need for cross-validation\n",
    "\n",
    "Repeatedly using the same test dataset to compare the performances of multiple trained models raised the concern of **data leakage**: suppose we tried 100 models (including various hyperparameter choices), and selected the champion model based on test accuracy. This highest test accuracy value may come from two sources:\n",
    "+ The trained champion model is indeed good\n",
    "+ We found a model that may or may not be good, but *happens to work well on the test dataset*\n",
    "\n",
    "To avoid the above data leakage problem, we usually prepare a third data sample, **the validation data**, that is used during hyperparameter tuning. After hyperparameter tuning is done, we then use the *never used before* test data to check its final performance.\n",
    "\n",
    "Nowadays, instead of manually creating a validation data, we often use cross validation to automate the process:\n",
    "+ [explanation of cross validation on wikipedia](https://en.wikipedia.org/wiki/Cross-validation_(statistics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain the data leak issue when doing hyperparameter tuning\n",
    "Thus the need for validation data\n",
    "And CV provides a good solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FOw15w6ScO2A"
   },
   "source": [
    "## Recapping the steps when using `GridSearchCV()`\n",
    "\n",
    "As in the code above, to use `GridSearchCV()`, we need to do the following.\n",
    "\n",
    "*Step 1.* Decide on which learning algorithm to use, e.g.\n",
    "\n",
    "`clf = DecisionTreeClassifier(random_state=1)`\n",
    "\n",
    "*Step 2.* Decide on what values to try for each of the chosen hyperparameters, e.g.\n",
    "\n",
    "```\n",
    "param_grid = {\n",
    "    'criterion' : [\"gini\", \"entropy\"],\n",
    "    'max_depth': np.arange(2,11,2),\n",
    "}    \n",
    "```\n",
    "\n",
    "*Step 3.* Then, call `GridSearchCV()` to try all these hyperparameter values for the chosen learning algorithm, e.g.\n",
    "\n",
    "`grid = GridSearchCV(estimator = clf, param_grid = param_grid, cv=3)`\n",
    "\n",
    "Additional comments on `GridSearchCV()`:\n",
    "+ It is similar to function `tune()` in Caret in R.\n",
    "+ `scikit-learn` provides a few alternatives of `GridSearchCV()` for hyperparameter tuning -- [see the user guide](https://scikit-learn.org/stable/modules/grid_search.html). \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using alternative metrics during hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example below, we switch the performance metrics from 'accuracy' to 'ROC AUC':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KasN14GhPz_T",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify the 'scoring' option in GridSearchCV()\n",
    "grid = GridSearchCV(estimator = clf, param_grid = param_grid, scoring='roc_auc', cv=3)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "print(f\"Best parameters are: {grid.best_params_}\")\n",
    "print(f\"The cross-validation ROC AUC is: {round(grid.best_score_,4)}\")\n",
    "\n",
    "# Accordingly, adjust the evaluation code\n",
    "y_predict = grid.best_estimator_.predict(X_test)\n",
    "y_predict_proba = grid.best_estimator_.predict_proba(X_test)[:,1]\n",
    "print(f\"The testing ROC AUC is: {roc_auc_score(y_test, y_predict_proba).round(4)}\")\n",
    "print(\"The confusion matrix is:\")\n",
    "cm = confusion_matrix(y_test, y_predict)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model persistence\n",
    "\n",
    "After we find our champion trained model, we need to save it (a.k.a., persist it) so that we don't have to go through the training process again in order to use the trained model. The steps for saving and reusing a trained model is called **model persistence**, and can be done using either the `pickle` package or the `joblib` package. Below we use the `joblib` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(grid.best_estimator_, 'clf_best.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that we can load & use the saved model\n",
    "clf_loaded = load('clf_best.joblib')\n",
    "clf_loaded.predict(X_test[0:11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caution: make sure you always pre-process new data exactly in the same way that you pre-processed the training data, before applying a saved model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KvJ53gjA33Ha"
   },
   "source": [
    "## Exercise: Create a kNN classifier, and tune its hyperparameter 'n_neighbors'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNNï¼šlecture 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ebqFDtI7uKaR"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "When n_neighbors=5, the accuracy is: 50.98%\n",
      "The confusion matrix is:\n",
      "[[155 143]\n",
      " [158 158]]\n",
      "\n",
      "When n_neighbors=10, the accuracy is: 50.49%\n",
      "The confusion matrix is:\n",
      "[[192 106]\n",
      " [198 118]]\n"
     ]
    }
   ],
   "source": [
    "y_predict = KNeighborsClassifier(n_neighbors=5).fit(X_train,y_train).predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_predict)\n",
    "print(f\"\\nWhen n_neighbors=5, the accuracy is: {accuracy:.2%}\")\n",
    "print(\"The confusion matrix is:\")\n",
    "print(confusion_matrix(y_test, y_predict))\n",
    "\n",
    "y_predict = KNeighborsClassifier(n_neighbors=10).fit(X_train,y_train).predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_predict)\n",
    "print(f\"\\nWhen n_neighbors=10, the accuracy is: {accuracy:.2%}\")\n",
    "print(\"The confusion matrix is:\")\n",
    "print(confusion_matrix(y_test, y_predict))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMYquq/jiL6dxDHhf0Kq9WV",
   "collapsed_sections": [],
   "name": "ML_5_HyperparameterTuning_and_XGBoost_filled.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
